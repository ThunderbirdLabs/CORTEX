# CORTEX - Enterprise RAG Platform

**Version 0.5.0** | [Security](#-security--compliance) | [Architecture](#%EF%B8%8F-architecture-overview) | [API Reference](#-api-reference) | [Deployment](#-deployment--production)

Enterprise-grade unified backend for **multi-source data ingestion** (Gmail, Outlook, Google Drive, file uploads) with **AI-powered hybrid RAG search** (vector + knowledge graph).

Built with FastAPI, LlamaIndex, Neo4j, Qdrant, and OpenAI.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#-key-features)
- [Architecture](#%EF%B8%8F-architecture-overview)
- [Security & Compliance](#-security--compliance)
  - [Authentication & Authorization](#authentication--authorization)
  - [Rate Limiting](#rate-limiting--dos-protection)
  - [Input Validation](#input-validation--sanitization)
  - [Security Headers](#security-headers)
- [Reliability & Resilience](#-reliability--resilience)
  - [Error Handling](#error-handling)
  - [Retry Mechanisms & Circuit Breakers](#retry-mechanisms--circuit-breakers)
  - [Background Jobs & Workers](#background-jobs--workers)
- [Data Flow](#-data-flow)
  - [Document Ingestion](#flow-1-universal-document-ingestion)
  - [AI Search](#flow-2-ai-search-hybrid-rag)
- [API Reference](#-api-reference)
- [Deployment & Production](#-deployment--production)
- [Codebase Structure](#%EF%B8%8F-codebase-structure)
- [Version History](#-version-history)

---

## Overview

**CORTEX** is a production-ready RAG (Retrieval-Augmented Generation) platform designed for Fortune 500 enterprises. It ingests documents from multiple sources, processes them through an AI pipeline, and enables intelligent search across your organization's knowledge base.

### What Makes CORTEX Enterprise-Grade?

| Feature | Implementation | Status |
|---------|---------------|--------|
| **Security** | JWT + API key auth, timing-safe comparisons, 7 security headers, rate limiting | âœ… Production |
| **Reliability** | 4 circuit breakers, 80+ try-catch blocks, graceful degradation | âœ… Production |
| **Scalability** | Background jobs (Dramatiq + Redis), connection pooling, batch processing | âœ… Production |
| **Compliance** | OWASP Top 10, CORS whitelist, PII sanitization, error tracking (Sentry) | âœ… Production |
| **Monitoring** | Structured logging, request tracing, performance metrics | âœ… Production |

---

## ğŸ¯ Key Features

### Multi-Source Ingestion
- **Email Sync**: Gmail, Outlook with incremental sync
- **Cloud Storage**: Google Drive with folder-level selection
- **File Uploads**: PDF, Word, Excel, PowerPoint, images (OCR via Google Cloud Vision)
- **Spam Filtering**: AI-powered business vs marketing classification
- **Deduplication**: SHA256 content hashing prevents duplicate ingestion

### Hybrid RAG Search
- **Vector Search**: Semantic similarity via Qdrant + OpenAI embeddings
- **Graph Search**: Relationship traversal via Neo4j + entity extraction
- **Intelligent Routing**: SubQuestionQueryEngine decomposes complex queries
- **Source Attribution**: Every answer cites original documents

### Knowledge Graph
- **10 Entity Types**: Person, Company, Deal, Task, Meeting, Payment, Material, Certification, Project, Role
- **19 Relationship Types**: Works_For, Reports_To, Client_Of, Supplies_Material, Attended_Meeting, etc.
- **Hourly Deduplication**: Vector similarity (0.92+) + Levenshtein distance (<3)
- **Graph-Aware Retrieval**: Entity embeddings for contextualized search

### Production-Ready Infrastructure
- **Background Jobs**: Async sync via Dramatiq + Redis with 3x auto-retry
- **Rate Limiting**: Per-user + per-IP, 8 protected endpoints
- **Error Recovery**: Circuit breakers with exponential backoff (OpenAI, Neo4j, Qdrant)
- **Memory Optimized**: Lazy loading, streaming uploads, 512MB Render-compatible
- **Monitoring**: Sentry error tracking with environment-aware sampling

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRONTEND (Vercel - Next.js)                     â”‚
â”‚         Modern React UI with OAuth, Chat, and Connections            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                                       â”‚
              â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NANGO (OAuth Proxy)   â”‚           â”‚   CORTEX BACKEND (Render)    â”‚
â”‚   - Gmail OAuth         â”‚           â”‚   FastAPI - main.py          â”‚
â”‚   - Outlook OAuth       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   - OAuth webhooks           â”‚
â”‚   - Google Drive OAuth  â”‚           â”‚   - Multi-source sync        â”‚
â”‚   - Token management    â”‚           â”‚   - Normalization            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚   SUPABASE (PostgreSQL)      â”‚
                                      â”‚   - documents table (UNIFIED)â”‚
                                      â”‚   - All content types        â”‚
                                      â”‚   - Content dedupe (SHA256)  â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚          UNIVERSAL INGESTION PIPELINE                       â”‚
                      â”‚          (UniversalIngestionPipeline)                       â”‚
                      â”‚                                                             â”‚
                      â”‚  1. SentenceSplitter â†’ Chunk text (512 chars, 50 overlap)  â”‚
                      â”‚  2. OpenAI Embedding â†’ text-embedding-3-small               â”‚
                      â”‚  3. SchemaLLMPathExtractor â†’ GPT-4o-mini entity extraction  â”‚
                      â”‚  4. Entity Embeddings â†’ Graph-aware retrieval               â”‚
                      â”‚  5. Parallel processing â†’ 4 workers                         â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   QDRANT CLOUD      â”‚         â”‚      NEO4J AURA      â”‚
                         â”‚   Vector Store      â”‚         â”‚   Property Graph     â”‚
                         â”‚                     â”‚         â”‚                      â”‚
                         â”‚ - Text chunks       â”‚         â”‚ - Document nodes     â”‚
                         â”‚ - Embeddings        â”‚         â”‚   (title|doc_id)     â”‚
                         â”‚ - Metadata          â”‚         â”‚ - EMAIL/PERSON nodes â”‚
                         â”‚ - 4-worker batch    â”‚         â”‚ - COMPANY nodes      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ - Relationships      â”‚
                                                         â”‚   (SENT_BY, WORKS_AT)â”‚
                                                         â”‚ - Entity embeddings  â”‚
                                                         â”‚                      â”‚
                                                         â”‚ + Hourly entity      â”‚
                                                         â”‚   deduplication      â”‚
                                                         â”‚   (vector similarity)â”‚
                                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     |
                                                     â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”€â”
                                    â”‚     HYBRID QUERY ENGINE             â”‚
                                    â”‚     (HybridQueryEngine)             â”‚
                                    â”‚                                     â”‚
                                    â”‚  SubQuestionQueryEngine combines:   â”‚
                                    â”‚  â”œâ”€ VectorStoreIndex (Qdrant)       â”‚
                                    â”‚  â””â”€ PropertyGraphIndex (Neo4j)      â”‚
                                    â”‚                                     â”‚
                                    â”‚  Routes sub-questions to best index â”‚
                                    â”‚  Synthesizes comprehensive answers  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                           User queries via:
                                           /api/v1/chat
                                           /api/v1/search
```

---

## ğŸ” Security & Compliance

**Security Grade: A-** (85/100) | **OWASP Top 10: Covered** | **Production-Ready: âœ…**

### Authentication & Authorization

#### 1. JWT Authentication (Supabase)
**Location**: [app/core/security.py:31-76](app/core/security.py#L31)

```python
async def get_current_user_id(
    credentials: HTTPAuthorizationCredentials = Depends(bearer_scheme),
    supabase: Client = Depends(get_supabase)
) -> str:
    """Validate Supabase JWT and extract user UUID."""
    response = supabase.auth.get_user(token)
    user_id = response.user.id
    # SECURITY: PII sanitization - logs only first 8 chars
    logger.debug(f"Authenticated user: {user_id[:8]}...")
    return user_id
```

**Protected Endpoints**: OAuth, sync, uploads, chat, search, emails

#### 2. API Key Authentication (Timing-Safe)
**Location**: [app/core/security.py:83-127](app/core/security.py#L83)

```python
# SECURITY: Constant-time comparison prevents timing attacks
if not hmac.compare_digest(api_key, settings.cortex_api_key):
    raise HTTPException(status_code=401, detail="Invalid API key")
```

**Protected Endpoints**: Search, deduplication management

**Configuration**:
```bash
# Backend (Render)
CORTEX_API_KEY=<32+ character random key>

# Frontend (Vercel)
NEXT_PUBLIC_CORTEX_API_KEY=<same key>
```

### Rate Limiting & DoS Protection

**Implementation**: [app/middleware/rate_limit.py](app/middleware/rate_limit.py)

#### Per-Endpoint Limits (8 endpoints protected)

| Endpoint | Rate Limit | Purpose |
|----------|-----------|---------|
| `POST /upload/file` | **10/hour** | Single file uploads |
| `POST /upload/files` | **5/hour** | Batch uploads (stricter) |
| `POST /api/v1/chat` | **20/minute** | Chat queries |
| `POST /api/v1/search` | **30/minute** | Search queries |
| `GET /sync/once` | **30/hour** | Manual Outlook sync |
| `GET /sync/once/gmail` | **30/hour** | Manual Gmail sync |
| `GET /sync/once/drive` | **5/hour** | Google Drive sync |
| `GET /connect/start` | **20/hour** | OAuth initiation |

#### Smart Rate Limiting Strategy
```python
def rate_limit_key_func(request: Request) -> str:
    """Uses user_id for authenticated requests, IP for unauthenticated"""
    if hasattr(request.state, "user_id"):
        return f"user:{user_id}"  # Prevents IP-switching bypass
    return f"ip:{get_remote_address(request)}"
```

**Default Global**: 100 requests/minute per IP (unauthenticated endpoints)

### Input Validation & Sanitization

#### File Upload Security (6 layers)
**Location**: [app/api/v1/routes/upload.py](app/api/v1/routes/upload.py)

1. **MIME Type Whitelist** (20+ allowed types)
   - PDF, Word, Excel, PowerPoint, Text, Images, CSV
   - Rejects executables, scripts, archives

2. **Filename Sanitization**
   ```python
   filename = Path(filename).name  # Remove path components (../../../etc/passwd)
   filename = re.sub(r'[^a-zA-Z0-9._-]', '_', filename)  # Remove special chars
   if filename.startswith('.'):
       filename = '_' + filename  # Prevent hidden files
   ```

3. **File Size Limits**
   - **Single upload**: 100MB max
   - **Batch upload**: 10 files max

4. **Streaming Upload** - Prevents memory exhaustion
   ```python
   file_bytes = bytearray()
   async for chunk in file.stream():
       if len(file_bytes) + len(chunk) > MAX_FILE_SIZE:
           raise HTTPException(413, "File too large")
       file_bytes.extend(chunk)
   ```

5. **Rate Limiting** - 10 uploads/hour (5/hour for batches)

6. **Error Isolation** - Per-file error handling in batch uploads

### Security Headers

**Implementation**: [app/middleware/security_headers.py](app/middleware/security_headers.py)

| Header | Value | Purpose |
|--------|-------|---------|
| `Strict-Transport-Security` | `max-age=31536000; includeSubDomains; preload` | HSTS (production only) |
| `X-Content-Type-Options` | `nosniff` | Prevent MIME sniffing |
| `X-Frame-Options` | `DENY` | Prevent clickjacking |
| `X-XSS-Protection` | `1; mode=block` | Browser XSS protection |
| `Referrer-Policy` | `strict-origin-when-cross-origin` | Control referrer info |
| `Content-Security-Policy` | `default-src 'none'; frame-ancestors 'none'` | Strict CSP |
| `Permissions-Policy` | `geolocation=(), microphone=(), camera=()` | Disable dangerous features |

### CORS Configuration

**Implementation**: [app/middleware/cors.py](app/middleware/cors.py)

**Allowed Origins** (explicit whitelist, no wildcards):
```python
# Production
allowed_origins = ["https://connectorfrontend.vercel.app"]

# Development
allowed_origins += ["http://localhost:3000", "http://localhost:5173", "http://localhost:8080"]

# SECURITY: "null" origin explicitly NOT included (prevents file:// attacks)
```

**Allowed Methods**: `GET, POST, PUT, DELETE, OPTIONS`
**Allowed Headers**: `Content-Type, Authorization, X-API-Key, X-Request-ID`
**Credentials**: Allowed (for JWT cookies)
**Preflight Cache**: 10 minutes

### PII Protection

**Strategy**: Sanitized logging across all authentication flows

```python
# BEFORE: logger.debug(f"Authenticated user: {user_id}")  # 36-char UUID = PII
# AFTER:  logger.debug(f"Authenticated user: {user_id[:8]}...")  # Only first 8 chars
```

**Applied in**:
- JWT authentication ([app/core/security.py:67-68](app/core/security.py#L67))
- Rate limiting ([app/middleware/rate_limit.py:36](app/middleware/rate_limit.py#L36))
- All user-related logging

---

## ğŸ’ª Reliability & Resilience

### Error Handling

#### 1. Global Error Handler
**Location**: [app/middleware/error_handler.py](app/middleware/error_handler.py)

```python
class ErrorHandlerMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        try:
            return await call_next(request)
        except Exception as exc:
            logger.error(
                f"Unhandled exception during request",
                exc_info=True,  # Full traceback to logs
                extra={"path": request.url.path, "method": request.method}
            )
            return JSONResponse(
                status_code=500,
                content={
                    "detail": "Internal server error",  # Generic message
                    "error_type": type(exc).__name__,
                    "path": request.url.path
                }
            )
```

**Coverage**: 80+ try-catch blocks across all API routes

#### 2. Request Logging
**Location**: [app/middleware/logging.py](app/middleware/logging.py)

**Metrics Tracked**:
- HTTP method, path, status code
- Response time (milliseconds)
- Client IP address
- Structured logging with `extra` fields

#### 3. Graceful Degradation

**Example**: RAG Pipeline Initialization
```python
try:
    from app.services.ingestion.llamaindex import UniversalIngestionPipeline
    rag_pipeline = UniversalIngestionPipeline()
    logger.info("âœ… RAG pipeline initialized")
except Exception as e:
    logger.warning(f"âš ï¸  Failed to initialize RAG pipeline: {e}")
    rag_pipeline = None  # App continues without pipeline
```

**Pattern Applied To**:
- RAG pipeline initialization
- Query engine initialization
- Sentry error tracking
- Optional dependencies

### Retry Mechanisms & Circuit Breakers

**Implementation**: [app/core/circuit_breakers.py](app/core/circuit_breakers.py)

#### 1. OpenAI Circuit Breaker (Search & Chat)

```python
@with_openai_retry  # 3 retries, exponential backoff
async def _execute_search_with_retry(engine, query_text: str):
    return await engine.query(query_text)
```

**Configuration**:
- **Max Retries**: 3 attempts
- **Backoff**: Exponential (2s â†’ 4s â†’ 8s, max 10s)
- **Retry Conditions**: `RateLimitError`, `APIConnectionError`, `APITimeoutError`

**Usage**: [app/api/v1/routes/search.py:39](app/api/v1/routes/search.py#L39), [app/api/v1/routes/chat.py:63](app/api/v1/routes/chat.py#L63)

#### 2. Neo4j Circuit Breaker (Graph Queries)

```python
@with_neo4j_retry  # 3 retries, exponential backoff
def neo4j_query(query: str):
    return driver.execute_query(query)
```

**Configuration**:
- **Max Retries**: 3 attempts
- **Backoff**: Exponential (1s â†’ 2s â†’ 4s, max 5s)
- **Retry Conditions**: Connection errors, timeouts

#### 3. Qdrant Circuit Breaker (Vector Queries)

```python
@with_qdrant_retry  # 3 retries, exponential backoff
async def qdrant_query(query_vector: List[float]):
    return await client.search(collection_name, query_vector)
```

**Configuration**:
- **Max Retries**: 3 attempts
- **Backoff**: Exponential (1s â†’ 2s â†’ 4s, max 5s)
- **Retry Conditions**: Connection errors, timeouts

#### 4. Generic Retry Decorator

```python
@with_retry(max_attempts=3, min_wait=1, max_wait=10)
async def my_external_api_call():
    ...
```

**Summary**: 4 circuit breaker patterns covering all external dependencies

### Background Jobs & Workers

**Framework**: Dramatiq + Redis
**Implementation**: [app/services/background/](app/services/background/)

#### Broker Configuration

```python
redis_broker = RedisBroker(
    url=settings.redis_url,
    middleware=[
        Prometheus(),           # Metrics/monitoring
        AgeLimit(),             # Prevent stale tasks
        Retries(max_retries=3), # Automatic retries
        Callbacks(),            # Success/failure handlers
        Pipelines(),            # Task chaining
        ShutdownNotifications()
    ]
)
```

#### Background Job Types (3 sync types)

**Location**: [app/services/background/tasks.py](app/services/background/tasks.py)

| Job Type | Retry | Pagination | Features |
|----------|-------|-----------|----------|
| **Gmail Sync** | 3x | 100/page | Incremental sync, cursor storage |
| **Outlook Sync** | 3x | 10/page | Delta links, attachment handling |
| **Google Drive Sync** | 3x | 50/page | Folder-level, selective sync |

#### Job Status Tracking

**Database Table**: `sync_jobs` (Supabase PostgreSQL)

**States**:
- `queued` â†’ Job created, waiting to run
- `running` â†’ Currently executing
- `completed` â†’ Successfully finished
- `failed` â†’ Error occurred (with error message)

**API Endpoint**: `GET /api/v1/sync/jobs/{job_id}`

```json
{
  "id": "uuid",
  "user_id": "uuid",
  "type": "gmail_sync",
  "status": "completed",
  "started_at": "2025-10-27T12:00:00Z",
  "completed_at": "2025-10-27T12:05:32Z",
  "result": {
    "messages_synced": 142,
    "emails_filtered": 58,
    "total_processed": 200,
    "errors": []
  }
}
```

#### Error Recovery Strategy

**Per-Record Error Handling** (continues on failure):
```python
for record in records:
    try:
        await ingest_document(record)
    except Exception as e:
        errors.append(f"Failed to process {record['id']}: {e}")
        # Continue processing other records
```

**Pagination with Error Recovery**:
```python
cursor = None
while has_more:
    try:
        result = await fetch_page(cursor, limit=10)
        # Process records...
        cursor = result.get("next_cursor")
    except Exception as e:
        errors.append(f"Failed to fetch page: {e}")
        break  # Stop pagination on fetch error
```

**Partial Success Reporting**:
```json
{
  "status": "partial_success",
  "messages_synced": 180,
  "errors": ["Failed to process attachment xyz.pdf: Timeout"]
}
```

### Connection Pooling

#### HTTP Client Pools (2 configurations)

**Main Client** ([app/core/dependencies.py:62-65](app/core/dependencies.py#L62)):
```python
http_client = httpx.AsyncClient(
    timeout=30.0,
    limits=httpx.Limits(
        max_keepalive_connections=10,
        max_connections=20
    )
)
```

**Background Job Client** ([app/services/background/tasks.py:24-27](app/services/background/tasks.py#L24)):
```python
http_client = httpx.AsyncClient(
    timeout=60.0,  # Longer timeout for background jobs
    limits=httpx.Limits(
        max_keepalive_connections=5,
        max_connections=10  # Smaller pool to avoid exhaustion
    )
)
```

### Resource Limits

| Resource | Limit | Purpose |
|----------|-------|---------|
| **LlamaIndex Semaphore** | 10 concurrent | Prevent memory exhaustion |
| **Spam Filter Batch** | 10 emails | OpenAI API cost control |
| **Deduplication Batch** | 50 entities | Neo4j transaction size |
| **Nango Pagination (Outlook)** | 10 records | Prevent timeout/memory issues |
| **Nango Pagination (Gmail)** | 100 records | Efficient batch processing |

### Monitoring & Observability

#### Sentry Error Tracking
**Configuration**: [main.py:74-94](main.py#L74)

```python
sentry_sdk.init(
    dsn=settings.sentry_dsn,
    environment=settings.environment,  # dev/staging/production
    traces_sample_rate=0.1,  # 10% of requests
    profiles_sample_rate=0.1,  # 10% of profiles
    integrations=[FastApiIntegration(), LoggingIntegration()]
)
```

**Captured Events**:
- Unhandled exceptions (global error handler)
- Failed API calls (circuit breakers)
- Background job failures (Dramatiq)
- Authentication failures (security.py)

### **Schema-Aware Auto-Indexing**
- âœ… Automatic Neo4j index creation at startup from `config.py` schema
- âœ… Dynamically generates indexes for all entity types in `POSSIBLE_ENTITIES`
- âœ… When you add new entity types, indexes are created automatically on restart
- âœ… 40-800x performance improvement vs unindexed queries (500ms â†’ 2ms)

---

## ğŸ“Š Data Flow

### FLOW 1: Universal Document Ingestion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FILE ARRIVES                                             â”‚
â”‚    - Upload: User uploads via API                           â”‚
â”‚    - Email: Synced from Gmail/Outlook                       â”‚
â”‚    - Drive: Pulled from Google Drive                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SPAM FILTER (Emails Only)                                â”‚
â”‚    Location: app/services/filters/openai_spam_detector.py   â”‚
â”‚    - Uses GPT-4o-mini to classify: BUSINESS or SPAM         â”‚
â”‚    - Checks business indicators first (fast bypass)         â”‚
â”‚    - SPAM = filtered out (not ingested)                     â”‚
â”‚    - BUSINESS = continues to next step                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. TEXT EXTRACTION (OCR for images/scanned PDFs)           â”‚
â”‚    Location: app/services/parsing/file_parser.py            â”‚
â”‚                                                              â”‚
â”‚    Strategy by file type:                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ PDFs:                                             â”‚    â”‚
â”‚    â”‚  â†’ Try fast text extraction first                â”‚    â”‚
â”‚    â”‚  â†’ If <100 chars (scanned PDF):                  â”‚    â”‚
â”‚    â”‚     1. Convert PDF to images (pdf2image)         â”‚    â”‚
â”‚    â”‚     2. Google Cloud Vision OCR each page         â”‚    â”‚
â”‚    â”‚     3. Combine all page text                     â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ Images (PNG/JPG/TIFF):                           â”‚    â”‚
â”‚    â”‚  â†’ Google Cloud Vision OCR (HIPAA-compliant)     â”‚    â”‚
â”‚    â”‚  â†’ Extract all text from image                   â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ Office Files (Word/Excel/PowerPoint):            â”‚    â”‚
â”‚    â”‚  â†’ Unstructured library parsing                  â”‚    â”‚
â”‚    â”‚  â†’ No OCR needed (text-based formats)            â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. DEDUPLICATION CHECK                                      â”‚
â”‚    - Generate content hash (SHA-256)                        â”‚
â”‚    - Check if already exists in documents table             â”‚
â”‚    - Skip if duplicate (based on content similarity)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. SAVE TO DOCUMENTS TABLE (Supabase PostgreSQL)           â”‚
â”‚    Table: documents (SOURCE OF TRUTH)                       â”‚
â”‚    Columns:                                                  â”‚
â”‚      - tenant_id (user ID) â†’ Data isolation                â”‚
â”‚      - source (gmail/gdrive/upload/slack)                   â”‚
â”‚      - document_type (email/pdf/file/attachment)            â”‚
â”‚      - content (extracted plain text)                       â”‚
â”‚      - content_hash (SHA-256 for deduplication)            â”‚
â”‚      - file_url (Supabase Storage URL)                      â”‚
â”‚      - metadata (JSONB - parsing info, OCR confidence)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. RAG INGESTION PIPELINE (Parallel)                       â”‚
â”‚    Location: app/services/ingestion/llamaindex/            â”‚
â”‚                                                              â”‚
â”‚    A. TEXT CHUNKING                                         â”‚
â”‚       - SentenceSplitter (1024 chars, 200 overlap)         â”‚
â”‚                                                              â”‚
â”‚    B. EMBEDDING                                             â”‚
â”‚       - OpenAI text-embedding-3-small                       â”‚
â”‚       - Each chunk gets vector embedding                    â”‚
â”‚                                                              â”‚
â”‚    C. QDRANT STORAGE (Vector Database)                     â”‚
â”‚       - Store chunks with embeddings                        â”‚
â”‚       - Metadata: document_id, chunk_index, source          â”‚
â”‚       - Enable semantic search                              â”‚
â”‚                                                              â”‚
â”‚    D. NEO4J STORAGE (Knowledge Graph)                      â”‚
â”‚       Step 1: Create Document Node                          â”‚
â”‚       Step 2: Entity Extraction (GPT-4o-mini)              â”‚
â”‚         â€¢ 10 entity types: PERSON, COMPANY, DEAL, etc.     â”‚
â”‚         â€¢ 19 relationship types: WORKS_FOR, CLIENT_OF, etc.â”‚
â”‚       Step 3: Create Entity Nodes + Relationships           â”‚
â”‚       Step 4: Link Document â†’ MENTIONS â†’ Entities          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. HOURLY ENTITY DEDUPLICATION (Neo4j only)                â”‚
â”‚    - Find similar entities (vector similarity > 0.92)       â”‚
â”‚    - Verify with Levenshtein distance (< 3 chars)           â”‚
â”‚    - Merge duplicates with apoc.refactor.mergeNodes         â”‚
â”‚    - Runs via Render cron job every 15 minutes             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. INDEXING COMPLETE âœ…                                     â”‚
â”‚    Document is now searchable via:                          â”‚
â”‚    â€¢ Vector search (Qdrant) - semantic similarity           â”‚
â”‚    â€¢ Graph queries (Neo4j) - relationship traversal         â”‚
â”‚    â€¢ SQL queries (Supabase) - metadata filtering            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FLOW 2: AI Search (Hybrid RAG)

```
1. USER QUERY â†’ POST /api/v1/chat or /api/v1/search
   - Rate limited: 20/min (chat), 30/min (search)
   - Authentication: JWT + API Key

2. QUERY REWRITING (with conversation context)
   - Rewrites query based on conversation history
   - Resolves pronouns, maintains context

3. HYBRID QUERY ENGINE (HybridQueryEngine)
   â””â”€> SubQuestionQueryEngine breaks down complex questions

4. PARALLEL RETRIEVAL (with circuit breakers)
   â”œâ”€> VectorStoreIndex (Qdrant) [@with_qdrant_retry]:
   â”‚   â”œâ”€> Embed query with OpenAI
   â”‚   â”œâ”€> Semantic search over text chunks
   â”‚   â””â”€> Return top K similar chunks (default: 10)
   â”‚
   â””â”€> PropertyGraphIndex (Neo4j) [@with_neo4j_retry]:
       â”œâ”€> Graph queries for relationships
       â”œâ”€> Entity lookups (PERSON, COMPANY, EMAIL)
       â””â”€> Return relevant entities + relationships

5. SYNTHESIS [@with_openai_retry]
   â”œâ”€> SubQuestionQueryEngine combines results
   â”œâ”€> GPT-4o-mini generates comprehensive answer
   â””â”€> Cites sources from both indexes

6. RESPONSE
   â””â”€> {
         "answer": "...",
         "source_count": 5,
         "sources": [
           {"node_id": "...", "text": "...", "score": 0.92, "file_url": "..."}
         ]
       }
```

---

## ğŸ”Œ API Reference

### Base URL
- **Production**: `https://your-app.onrender.com`
- **Staging**: `https://your-app-staging.onrender.com`

### Authentication

All authenticated endpoints require:
```bash
Authorization: Bearer <supabase_jwt_token>
```

Search and deduplication endpoints also require:
```bash
X-API-Key: <cortex_api_key>
```

### Endpoints

#### OAuth & Connections

| Endpoint | Method | Auth | Rate Limit | Description |
|----------|--------|------|-----------|-------------|
| `GET /` | GET | None | - | API info |
| `GET /health` | GET | None | - | Health check |
| `GET /status` | GET | JWT | - | Connection status |
| `GET /connect/start` | GET | JWT | 20/hour | Initiate OAuth |
| `POST /nango/webhook` | POST | None | - | Nango webhook |

**Example: Initiate OAuth**
```bash
curl -H "Authorization: Bearer <jwt>" \
  "https://api.cortex.com/connect/start?provider=gmail"

# Response
{
  "authorization_url": "https://api.nango.dev/oauth/connect/...",
  "session_token": "..."
}
```

#### Data Sync

| Endpoint | Method | Auth | Rate Limit | Description |
|----------|--------|------|-----------|-------------|
| `GET /sync/once` | GET | JWT | 30/hour | Manual Outlook sync |
| `GET /sync/once/gmail` | GET | JWT | 30/hour | Manual Gmail sync |
| `GET /sync/once/drive` | GET | JWT | 5/hour | Manual Drive sync |
| `GET /sync/jobs/{job_id}` | GET | JWT | - | Get job status |

**Example: Trigger Gmail Sync**
```bash
curl -H "Authorization: Bearer <jwt>" \
  "https://api.cortex.com/sync/once/gmail"

# Response
{
  "status": "accepted",
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": "Gmail sync job queued"
}
```

**Example: Check Job Status**
```bash
curl -H "Authorization: Bearer <jwt>" \
  "https://api.cortex.com/sync/jobs/550e8400-e29b-41d4-a716-446655440000"

# Response
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "type": "gmail_sync",
  "status": "completed",
  "started_at": "2025-10-27T12:00:00Z",
  "completed_at": "2025-10-27T12:05:32Z",
  "result": {
    "messages_synced": 142,
    "emails_filtered": 58,
    "total_processed": 200
  }
}
```

#### Search & Chat

| Endpoint | Method | Auth | Rate Limit | Description |
|----------|--------|------|-----------|-------------|
| `POST /api/v1/search` | POST | JWT + API Key | 30/minute | Hybrid RAG search |
| `POST /api/v1/chat` | POST | JWT | 20/minute | Chat interface |

**Example: Hybrid Search**
```bash
curl -X POST https://api.cortex.com/api/v1/search \
  -H "Authorization: Bearer <jwt>" \
  -H "X-API-Key: <api_key>" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the key points from the Q4 report?",
    "vector_limit": 5,
    "graph_limit": 5,
    "conversation_history": []
  }'

# Response
{
  "success": true,
  "query": "What are the key points from the Q4 report?",
  "answer": "Based on the Q4 report, the key points are...",
  "vector_results": [...],
  "graph_results": [...],
  "num_episodes": 3,
  "message": "Found 3 relevant documents"
}
```

#### File Management

| Endpoint | Method | Auth | Rate Limit | Description |
|----------|--------|------|-----------|-------------|
| `POST /api/v1/upload/file` | POST | JWT | 10/hour | Upload single file |
| `POST /api/v1/upload/files` | POST | JWT | 5/hour | Upload multiple files |
| `GET /api/v1/emails/{episode_id}` | GET | JWT | - | Get full email |

**Example: Upload File**
```bash
curl -X POST https://api.cortex.com/api/v1/upload/file \
  -H "Authorization: Bearer <jwt>" \
  -F "file=@document.pdf" \
  -F "source=upload"

# Response
{
  "success": true,
  "document_id": "123",
  "message": "File uploaded and ingested successfully"
}
```

#### Deduplication Management

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `POST /api/v1/deduplication/run` | POST | API Key | Trigger manual deduplication |
| `GET /api/v1/deduplication/stats` | GET | API Key | Get deduplication statistics |
| `GET /api/v1/deduplication/status` | GET | API Key | Get system status |

**Example: Trigger Deduplication**
```bash
curl -X POST https://api.cortex.com/api/v1/deduplication/run \
  -H "X-API-Key: <api_key>" \
  -H "Content-Type: application/json" \
  -d '{
    "dry_run": false,
    "similarity_threshold": 0.92
  }'

# Response
{
  "status": "success",
  "clusters_found": 15,
  "entities_merged": 42,
  "duration_seconds": 12.3
}
```

---

## ğŸš€ Deployment & Production

### Prerequisites

- Python 3.13+
- PostgreSQL (Supabase)
- Redis (for background jobs)
- Qdrant Cloud account
- Neo4j Aura database
- OpenAI API key
- Nango account (OAuth proxy)
- Google Cloud account (for Vision OCR)

### Environment Variables

**Complete list**: See [.env.example](.env.example)

#### Critical Variables

```bash
# Environment
ENVIRONMENT=production  # REQUIRED: Enables HSTS, disables debug endpoints

# Security
CORTEX_API_KEY=<32+ char random key>  # REQUIRED: Generate with:
# python3 -c "import secrets, base64; print(base64.urlsafe_b64encode(secrets.token_bytes(32)).decode())"

# Database (Supabase)
DATABASE_URL=postgresql://...
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=...
SUPABASE_SERVICE_KEY=...  # For server-side operations

# OAuth (Nango)
NANGO_SECRET=...
NANGO_PROVIDER_KEY_GMAIL=google-mail
NANGO_PROVIDER_KEY_GOOGLE_DRIVE=google-drive
NANGO_PROVIDER_KEY_OUTLOOK=outlook

# RAG System
QDRANT_URL=https://...
QDRANT_API_KEY=...
QDRANT_COLLECTION_NAME=cortex_documents
NEO4J_URI=neo4j+s://...
NEO4J_USER=neo4j
NEO4J_PASSWORD=...
OPENAI_API_KEY=sk-proj-...

# Google Cloud Vision (OCR)
GOOGLE_APPLICATION_CREDENTIALS={"type":"service_account",...}

# Background Jobs
REDIS_URL=redis://...

# Monitoring (Optional)
SENTRY_DSN=https://...  # For error tracking
```

### Database Setup

**Location**: [migrations/](migrations/)

```sql
-- Documents table (unified storage)
CREATE TABLE documents (
  id BIGSERIAL PRIMARY KEY,
  tenant_id TEXT NOT NULL,
  source TEXT NOT NULL,
  source_id TEXT NOT NULL,
  document_type TEXT NOT NULL,
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  content_hash TEXT,  -- SHA-256 for deduplication
  file_url TEXT,      -- Supabase Storage URL
  file_type TEXT,
  file_size BIGINT,
  mime_type TEXT,
  raw_data JSONB,
  metadata JSONB,
  parent_document_id BIGINT,
  source_created_at TIMESTAMPTZ,
  source_modified_at TIMESTAMPTZ,
  ingested_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(tenant_id, source, source_id)
);

CREATE INDEX idx_documents_tenant ON documents(tenant_id);
CREATE INDEX idx_documents_content_hash ON documents(tenant_id, content_hash, source);
CREATE INDEX idx_documents_source ON documents(tenant_id, source);

-- Sync jobs table (background job tracking)
CREATE TABLE sync_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id TEXT NOT NULL,
  type TEXT NOT NULL,  -- gmail_sync, drive_sync, outlook_sync
  status TEXT NOT NULL DEFAULT 'queued',  -- queued, running, completed, failed
  started_at TIMESTAMPTZ,
  completed_at TIMESTAMPTZ,
  result JSONB,
  error_message TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_sync_jobs_user ON sync_jobs(user_id);
CREATE INDEX idx_sync_jobs_status ON sync_jobs(status);

-- Supabase Storage bucket
INSERT INTO storage.buckets (id, name, public)
VALUES ('documents', 'documents', true);
```

### Render Deployment

**File**: [render-build.sh](render-build.sh)

1. **Create new Web Service**
   - Runtime: Python 3
   - Build Command: `./render-build.sh`
   - Start Command: `uvicorn main:app --host 0.0.0.0 --port $PORT`

2. **Add Environment Variables** (see above)

3. **Set up Cron Job** (for deduplication)
   - Schedule: `*/15 * * * *` (every 15 minutes)
   - Command: `python -m app.services.deduplication.run_dedup_cli`

4. **Configure Health Check**
   - Path: `/health`
   - Expected Status: 200
   - Timeout: 30s

### Vercel Frontend Deployment

**Required Environment Variables**:
```bash
NEXT_PUBLIC_CORTEX_API_KEY=<same as backend CORTEX_API_KEY>
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=...
NEXT_PUBLIC_API_URL=https://your-app.onrender.com
```

### Post-Deployment Checklist

- [ ] Set `ENVIRONMENT=production` on Render
- [ ] Generate and set `CORTEX_API_KEY` (32+ chars)
- [ ] Verify security headers: `curl -I https://your-api.onrender.com/health`
- [ ] Test OAuth flow: Gmail, Outlook, Google Drive
- [ ] Trigger test sync and verify job status
- [ ] Upload test file and verify ingestion
- [ ] Run test search query
- [ ] Check Sentry for errors (if configured)
- [ ] Verify rate limiting with burst requests
- [ ] Test deduplication cron job execution

---

## ğŸ—‚ï¸ Codebase Structure

```
cortex/
â”œâ”€â”€ main.py                              # FastAPI entry point
â”‚
â”œâ”€â”€ app/                                 # Main application
â”‚   â”œâ”€â”€ core/                            # Infrastructure
â”‚   â”‚   â”œâ”€â”€ config.py                    # Pydantic Settings (all env vars)
â”‚   â”‚   â”œâ”€â”€ dependencies.py              # DI (HTTP, Supabase, RAG pipeline)
â”‚   â”‚   â”œâ”€â”€ security.py                  # JWT + API key auth (timing-safe)
â”‚   â”‚   â””â”€â”€ circuit_breakers.py          # Retry decorators (OpenAI, Neo4j, Qdrant)
â”‚   â”‚
â”‚   â”œâ”€â”€ middleware/                      # Request processing
â”‚   â”‚   â”œâ”€â”€ error_handler.py             # Global exception handling
â”‚   â”‚   â”œâ”€â”€ logging.py                   # Request logging (metrics)
â”‚   â”‚   â”œâ”€â”€ security_headers.py          # OWASP security headers
â”‚   â”‚   â”œâ”€â”€ rate_limit.py                # Per-user + per-IP rate limiting
â”‚   â”‚   â””â”€â”€ cors.py                      # CORS configuration (explicit whitelist)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/schemas/                  # Pydantic models
â”‚   â”‚   â”œâ”€â”€ connector.py                 # OAuth, webhooks
â”‚   â”‚   â”œâ”€â”€ sync.py                      # Sync operations
â”‚   â”‚   â”œâ”€â”€ search.py                    # Search request/response
â”‚   â”‚   â”œâ”€â”€ ingestion.py                 # Document models
â”‚   â”‚   â””â”€â”€ knowledge_graph.py           # Graph entity types
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                        # Business logic
â”‚   â”‚   â”œâ”€â”€ connectors/                  # Data connectors
â”‚   â”‚   â”‚   â”œâ”€â”€ gmail.py                 # Gmail normalization
â”‚   â”‚   â”‚   â”œâ”€â”€ google_drive.py          # Drive file handling
â”‚   â”‚   â”‚   â””â”€â”€ microsoft_graph.py       # Outlook sync
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ nango/                       # OAuth & sync
â”‚   â”‚   â”‚   â”œâ”€â”€ nango_client.py          # Nango API client
â”‚   â”‚   â”‚   â”œâ”€â”€ drive_client.py          # Drive-specific actions
â”‚   â”‚   â”‚   â”œâ”€â”€ drive_sync.py            # Drive sync engine
â”‚   â”‚   â”‚   â”œâ”€â”€ sync_engine.py           # Email sync orchestration (pagination, error recovery)
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py              # Connection management
â”‚   â”‚   â”‚   â””â”€â”€ persistence.py           # Data persistence
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ingestion/                   # RAG pipeline
â”‚   â”‚   â”‚   â””â”€â”€ llamaindex/
â”‚   â”‚   â”‚       â”œâ”€â”€ config.py            # LlamaIndex configuration
â”‚   â”‚   â”‚       â”œâ”€â”€ ingestion_pipeline.py # Universal ingestion
â”‚   â”‚   â”‚       â””â”€â”€ query_engine.py      # Hybrid query engine
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ parsing/                     # File parsing
â”‚   â”‚   â”‚   â””â”€â”€ file_parser.py           # Universal file parser (lazy-loaded)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ filters/                     # Content filters
â”‚   â”‚   â”‚   â””â”€â”€ openai_spam_detector.py  # AI-powered spam filter
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ deduplication/               # Deduplication
â”‚   â”‚   â”‚   â”œâ”€â”€ dedupe_service.py        # Content deduplication (SHA256)
â”‚   â”‚   â”‚   â”œâ”€â”€ entity_deduplication.py  # Entity deduplication (vector similarity)
â”‚   â”‚   â”‚   â””â”€â”€ run_dedup_cli.py         # Cron job entry point
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ background/                  # Background jobs
â”‚   â”‚   â”‚   â”œâ”€â”€ broker.py                # Dramatiq broker config (Redis)
â”‚   â”‚   â”‚   â””â”€â”€ tasks.py                 # Background job definitions (Gmail, Outlook, Drive)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ universal/                   # Universal ingestion
â”‚   â”‚   â”‚   â””â”€â”€ ingest.py                # Unified ingestion flow
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ search/                      # (Reserved for future query rewriting)
â”‚   â”‚
â”‚   â””â”€â”€ api/v1/routes/                   # API endpoints (v1)
â”‚       â”œâ”€â”€ health.py                    # Health checks
â”‚       â”œâ”€â”€ oauth.py                     # OAuth flow (Gmail/Drive/Outlook)
â”‚       â”œâ”€â”€ webhook.py                   # Nango webhooks
â”‚       â”œâ”€â”€ sync.py                      # Manual sync endpoints + job status
â”‚       â”œâ”€â”€ search.py                    # Hybrid RAG search
â”‚       â”œâ”€â”€ chat.py                      # Chat interface
â”‚       â”œâ”€â”€ emails.py                    # Email retrieval
â”‚       â”œâ”€â”€ upload.py                    # File upload (with security validations)
â”‚       â””â”€â”€ deduplication.py             # Deduplication management
â”‚
â”œâ”€â”€ migrations/                          # Database migrations
â”‚   â”œâ”€â”€ create_documents_table.sql
â”‚   â”œâ”€â”€ create_sync_jobs_table.sql
â”‚   â””â”€â”€ create_storage_bucket.sql
â”‚
â”œâ”€â”€ docs/                                # Documentation
â”‚   â”œâ”€â”€ SECURITY_FIXES_2025-10-27.md    # Security audit report
â”‚   â””â”€â”€ guides/
â”‚       â””â”€â”€ UNIFIED_INGESTION_SETUP.md  # Ingestion setup guide
â”‚
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ runtime.txt                          # Python 3.13
â”œâ”€â”€ render-build.sh                      # Render deployment script
â””â”€â”€ README.md                            # This file
```

---

## ğŸ“š Version History

### **v0.5.0 (Current) - Enterprise Security & Reliability**
**Released**: 2025-10-27

#### Security Hardening
- âœ… **Timing-safe API key validation** (`hmac.compare_digest`)
- âœ… **7 security headers**: HSTS, CSP, X-Frame-Options, X-Content-Type-Options, Referrer-Policy, Permissions-Policy, X-XSS-Protection
- âœ… **Rate limiting on 8 endpoints**: Uploads (10/h), chat (20/m), search (30/m), sync (30/h)
- âœ… **File upload security**: MIME whitelist, filename sanitization, 100MB limit, streaming
- âœ… **CORS hardening**: Explicit whitelist, no wildcards, removed "null" origin
- âœ… **PII protection**: Sanitized logging (user_id truncated to 8 chars)
- âœ… **Environment-based configuration**: HSTS + debug endpoint disabled in production

#### Reliability & Resilience
- âœ… **4 circuit breaker patterns**: OpenAI, Neo4j, Qdrant, generic (3x retry, exponential backoff)
- âœ… **Background job framework**: Dramatiq + Redis with 3x auto-retry
- âœ… **Job status tracking**: Database-backed with queued/running/completed/failed states
- âœ… **Error recovery**: Per-record error handling, pagination with error accumulation
- âœ… **Global error handler**: Structured logging with full tracebacks
- âœ… **Connection pooling**: HTTP client pools (main: 20 conn, background: 10 conn)
- âœ… **Graceful degradation**: Optional component initialization with fallbacks

#### Production Optimizations
- âœ… **Sentry error tracking**: Environment-aware with 10% sampling
- âœ… **Request logging**: Response time tracking, structured logs
- âœ… **Resource limits**: Semaphore (10), batch sizes (10-100), pagination limits
- âœ… **Lazy loading**: Query engine + RAG pipeline initialization

**Security Grade**: A- (85/100)

---

### **v0.4.5 - Production RAG System**
**Released**: 2025-10-15

#### Schema-Validated Knowledge Graph
- âœ… **SchemaLLMPathExtractor** - Strict entity/relationship validation
- âœ… 10 entity types (PERSON, COMPANY, EMAIL, DOCUMENT, DEAL, TASK, MEETING, PAYMENT, TOPIC, EVENT)
- âœ… 19 relationship types (SENT_BY, WORKS_AT, MENTIONS, PAID_BY, etc.)
- âœ… Entity embeddings for graph-aware retrieval
- âœ… Unique document IDs (`title|doc_id`) - prevents duplicate merging
- âœ… Neo4j label reordering for better visualization

#### Hybrid Query Engine
- âœ… **SubQuestionQueryEngine** - Intelligent query decomposition
- âœ… **VectorStoreIndex** (Qdrant) - Semantic search over chunks
- âœ… **PropertyGraphIndex** (Neo4j) - Graph queries over entities
- âœ… Automatic routing to best retrieval strategy
- âœ… Multi-strategy synthesis for comprehensive answers

#### Entity Deduplication System
- âœ… **Vector similarity** (cosine > 0.92) + Levenshtein distance (< 3 chars)
- âœ… Hourly scheduled deduplication (cron job)
- âœ… API endpoints for manual triggering (`/api/v1/deduplication/run`)
- âœ… Dry-run mode for preview before merging
- âœ… Prevents array IDs (fixed `title|doc_id` bug)
- âœ… Configurable thresholds via environment variables

#### Production Fixes
- âœ… Fixed array ID bug (toString() errors in Neo4j queries)
- âœ… Fixed entity extraction field names (sender_name, to_addresses)
- âœ… Removed 464 lines of dead code
- âœ… Fixed encoding issues for Python 3.13
- âœ… Memory-optimized for Render (512MB)

---

### **v0.3.0 - Google Drive & Universal Ingestion**
**Released**: 2025-09-20

- âœ… Google Drive OAuth & incremental sync
- âœ… Universal ingestion pipeline (any source â†’ RAG)
- âœ… Content-based deduplication (SHA256)
- âœ… Google Cloud Vision OCR (replaces AWS Textract)
- âœ… Modern Aetheris-style frontend
- âœ… Memory optimizations (lazy loading, 512MB fit)

---

### **v0.2.0 - Enterprise Refactor**
**Released**: 2025-08-10

- âœ… Unified backend architecture
- âœ… Dependency injection pattern
- âœ… Type-safe configuration (Pydantic Settings)
- âœ… API versioning (`/api/v1/`)

---

### **v0.1.0 - Initial Release**
**Released**: 2025-07-01

- Email sync (Gmail/Outlook)
- Basic RAG search
- Frontend foundation
- Supabase authentication

---

## ğŸ§ª Testing

### Health Check
```bash
curl https://your-app.onrender.com/health
# Expected: {"status": "healthy"}
```

### Connection Status
```bash
curl -H "Authorization: Bearer <jwt>" \
  https://your-app.onrender.com/status
```

### Manual Drive Sync
```bash
curl -H "Authorization: Bearer <jwt>" \
  "https://your-app.onrender.com/sync/once/drive"
```

### RAG Search
```bash
curl -X POST https://your-app.onrender.com/api/v1/search \
  -H "Authorization: Bearer <jwt>" \
  -H "X-API-Key: <api-key>" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the key points from the Q4 report?",
    "vector_limit": 5,
    "graph_limit": 5
  }'
```

---

## ğŸ› Troubleshooting

### "Empty Response" in chat
- No data indexed yet. Go to Connections â†’ Sync Gmail/Drive first

### "Out of Memory" on Render
- Verify you're on v0.5.0 (lazy-loaded parsers, optimized chunking)
- Check memory usage in Render dashboard
- Upgrade to paid tier if needed

### Google Workspace files show garbled text
- Fixed in v0.3.0+ - uses proper export MIME types
- Docs/Slides â†’ `text/plain`
- Sheets â†’ `text/csv`

### "Invalid API key" errors
- Verify `CORTEX_API_KEY` is set in Render environment
- Verify `NEXT_PUBLIC_CORTEX_API_KEY` is set in Vercel environment
- Both must have the same value

### Rate limit errors (429)
- Check rate limits in [Rate Limiting](#rate-limiting--dos-protection) section
- Upgrade to higher limits if needed (contact support)

### Background sync jobs stuck in "queued" state
- Check Redis connection: `redis-cli ping` should return `PONG`
- Verify Dramatiq workers are running: Check Render logs for "Worker started"
- Restart web service if needed

---

## ğŸ“ License

Proprietary - ThunderbirdLabs

---

## ğŸ’¬ Support & Contributing

- **Issues**: Report bugs at [GitHub Issues](https://github.com/ThunderbirdLabs/CORTEX/issues)
- **Documentation**: See [docs/](docs/) folder
- **API Support**: Email support@thunderbirdlabs.com

---

**Built with â¤ï¸ by ThunderbirdLabs**

Technologies: FastAPI â€¢ LlamaIndex â€¢ Neo4j â€¢ Qdrant â€¢ OpenAI â€¢ Dramatiq â€¢ Redis â€¢ Supabase â€¢ Vercel
