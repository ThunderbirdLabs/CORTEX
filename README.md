# Cortex - Enterprise RAG Platform
**v0.4.5**

Enterprise-grade unified backend for **multi-source data ingestion** (Gmail, Outlook, Google Drive, file uploads) with **AI-powered hybrid RAG search** (vector + knowledge graph).

Built with FastAPI, LlamaIndex, Neo4j, Qdrant, and OpenAI.

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRONTEND (Vercel - Next.js)                     â”‚
â”‚         Modern React UI with OAuth, Chat, and Connections            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                                       â”‚
              â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NANGO (OAuth Proxy)   â”‚           â”‚   CORTEX BACKEND (Render)    â”‚
â”‚   - Gmail OAuth         â”‚           â”‚   FastAPI - main.py          â”‚
â”‚   - Outlook OAuth       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   - OAuth webhooks           â”‚
â”‚   - Google Drive OAuth  â”‚           â”‚   - Multi-source sync        â”‚
â”‚   - Token management    â”‚           â”‚   - Normalization            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚   SUPABASE (PostgreSQL)      â”‚
                                      â”‚   - documents table (UNIFIED)â”‚
                                      â”‚   - All content types        â”‚
                                      â”‚   - Content dedupe (SHA256)  â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚          UNIVERSAL INGESTION PIPELINE                       â”‚
                      â”‚          (UniversalIngestionPipeline)                       â”‚
                      â”‚                                                             â”‚
                      â”‚  1. SentenceSplitter â†’ Chunk text (512 chars, 50 overlap)  â”‚
                      â”‚  2. OpenAI Embedding â†’ text-embedding-3-small               â”‚
                      â”‚  3. SchemaLLMPathExtractor â†’ GPT-4o-mini entity extraction  â”‚
                      â”‚  4. Entity Embeddings â†’ Graph-aware retrieval               â”‚
                      â”‚  5. Parallel processing â†’ 4 workers                         â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   QDRANT CLOUD      â”‚         â”‚      NEO4J AURA      â”‚
                         â”‚   Vector Store      â”‚         â”‚   Property Graph     â”‚
                         â”‚                     â”‚         â”‚                      â”‚
                         â”‚ - Text chunks       â”‚         â”‚ - Document nodes     â”‚
                         â”‚ - Embeddings        â”‚         â”‚   (title|doc_id)     â”‚
                         â”‚ - Metadata          â”‚         â”‚ - EMAIL/PERSON nodes â”‚
                         â”‚ - 4-worker batch    â”‚         â”‚ - COMPANY nodes      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ - Relationships      â”‚
                                                         â”‚   (SENT_BY, WORKS_AT)â”‚
                                                         â”‚ - Entity embeddings  â”‚
                                                         â”‚                      â”‚
                                                         â”‚ + Hourly entity      â”‚
                                                         â”‚   deduplication      â”‚
                                                         â”‚   (vector similarity)â”‚
                                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     |
                                                     â”‚                 
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”€â”
                                    â”‚     HYBRID QUERY ENGINE             â”‚
                                    â”‚     (HybridQueryEngine)             â”‚
                                    â”‚                                     â”‚
                                    â”‚  SubQuestionQueryEngine combines:   â”‚
                                    â”‚  â”œâ”€ VectorStoreIndex (Qdrant)       â”‚
                                    â”‚  â””â”€ PropertyGraphIndex (Neo4j)      â”‚
                                    â”‚                                     â”‚
                                    â”‚  Routes sub-questions to best index â”‚
                                    â”‚  Synthesizes comprehensive answers  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                           User queries via:
                                           /api/v1/chat
                                           /api/v1/search
```

---

## ğŸ’¡ How It Works (Simple Explanation)

**Think of Cortex as an AI assistant that reads all your emails and documents, then answers questions about them.**

### The Journey of Your Data:

1. **ğŸ“¥ Collection** - Connect your Gmail, Outlook, or Google Drive. Cortex fetches your emails and documents.

2. **ğŸ§¹ Cleanup** - Removes duplicates automatically (using content fingerprinting).

3. **ğŸ’¾ Storage** - Saves everything in a database (Supabase) so you never lose it.

4. **ğŸ¤– AI Processing** - This is where the magic happens:
   - **Chunking**: Breaks long documents into smaller pieces (like paragraphs)
   - **Embedding**: Converts text into numbers that AI can search through
   - **Entity Extraction**: Identifies people, companies, deals, and relationships
   - All of this gets stored in two specialized databases for fast searching

5. **ğŸ’¬ Asking Questions** - When you ask "What did Sarah say about the Q4 report?":
   - Searches through chunks for relevant content (vector search)
   - Looks up people and relationships (graph search)
   - Combines everything into a smart answer
   - Shows you the sources so you can verify

### Why Two Databases?
- **Qdrant** (Vector Store): Fast at finding similar content - like Google for your data
- **Neo4j** (Knowledge Graph): Understands relationships - like knowing Sarah works at Acme Corp and sent 5 emails about Q4

Together, they give you comprehensive answers with sources you can trust.

---

## ğŸš€ What's New in v0.4.5

### **Schema-Validated Knowledge Graph**
- âœ… **SchemaLLMPathExtractor** - Strict entity/relationship validation
- âœ… 10 entity types (PERSON, COMPANY, EMAIL, DOCUMENT, DEAL, TASK, MEETING, PAYMENT, TOPIC, EVENT)
- âœ… 19 relationship types (SENT_BY, WORKS_AT, MENTIONS, PAID_BY, etc.)
- âœ… Entity embeddings for graph-aware retrieval
- âœ… Unique document IDs (`title|doc_id`) - prevents duplicate merging
- âœ… Neo4j label reordering for better visualization

### **Hybrid Query Engine**
- âœ… **SubQuestionQueryEngine** - Intelligent query decomposition
- âœ… **VectorStoreIndex** (Qdrant) - Semantic search over chunks
- âœ… **PropertyGraphIndex** (Neo4j) - Graph queries over entities
- âœ… Automatic routing to best retrieval strategy
- âœ… Multi-strategy synthesis for comprehensive answers

### **Entity Deduplication System**
- âœ… **Vector similarity** (cosine > 0.92) + Levenshtein distance (< 3 chars)
- âœ… Hourly scheduled deduplication (APScheduler)
- âœ… API endpoints for manual triggering (`/api/v1/deduplication/run`)
- âœ… Dry-run mode for preview before merging
- âœ… Prevents array IDs (fixed `title|doc_id` bug)
- âœ… Configurable thresholds via environment variables

### **Universal Ingestion Pipeline**
- âœ… Dual ingestion: Qdrant (chunks) + Neo4j (entities/documents)
- âœ… Content-based deduplication (SHA256 hashing)
- âœ… Batch processing with 4 workers
- âœ… 100k character limit per document (cost control)
- âœ… Any source â†’ unified format â†’ RAG
- âœ… Lightweight file parsing (lazy-loaded)

### **Production Fixes**
- âœ… Fixed array ID bug (toString() errors in Neo4j queries)
- âœ… Fixed entity extraction field names (sender_name, to_addresses)
- âœ… Removed 464 lines of dead code
- âœ… Fixed encoding issues for Python 3.13
- âœ… Memory-optimized for Render (512MB)

### **Schema-Aware Auto-Indexing**
- âœ… Automatic Neo4j index creation at startup from `config.py` schema
- âœ… Dynamically generates indexes for all entity types in `POSSIBLE_ENTITIES`
- âœ… When you add new entity types, indexes are created automatically on restart
- âœ… 40-800x performance improvement vs unindexed queries (500ms â†’ 2ms)

---

## ğŸ“Š Data Flow

### **FLOW 1: Universal Document Ingestion (End-to-End)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FILE ARRIVES                                             â”‚
â”‚    - Upload: User uploads via API                           â”‚
â”‚    - Email: Synced from Gmail/Outlook                       â”‚
â”‚    - Drive: Pulled from Google Drive                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SPAM FILTER (Emails Only)                                â”‚
â”‚    Location: app/services/filters/openai_spam_detector.py   â”‚
â”‚    - Uses GPT-4o-mini to classify: BUSINESS or SPAM         â”‚
â”‚    - Checks business indicators first (fast bypass)         â”‚
â”‚    - SPAM = filtered out (not ingested)                     â”‚
â”‚    - BUSINESS = continues to next step                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. UNIVERSAL INGESTION ENTRY                                â”‚
â”‚    Location: app/services/universal/ingest.py               â”‚
â”‚    Function: ingest_document_universal()                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. TEXT EXTRACTION (OCR for images/scanned PDFs)           â”‚
â”‚    Location: app/services/parsing/file_parser.py            â”‚
â”‚                                                              â”‚
â”‚    Strategy by file type:                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ PDFs:                                             â”‚    â”‚
â”‚    â”‚  â†’ Try fast text extraction first                â”‚    â”‚
â”‚    â”‚  â†’ If <100 chars (scanned PDF):                  â”‚    â”‚
â”‚    â”‚     1. Convert PDF to images (pdf2image)         â”‚    â”‚
â”‚    â”‚     2. Google Cloud Vision OCR each page         â”‚    â”‚
â”‚    â”‚     3. Combine all page text                     â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ Images (PNG/JPG/TIFF):                           â”‚    â”‚
â”‚    â”‚  â†’ Google Cloud Vision OCR (HIPAA-compliant)     â”‚    â”‚
â”‚    â”‚  â†’ Extract all text from image                   â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ Office Files (Word/Excel/PowerPoint):            â”‚    â”‚
â”‚    â”‚  â†’ Unstructured library parsing                  â”‚    â”‚
â”‚    â”‚  â†’ No OCR needed (text-based formats)            â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚    Result: Plain text + metadata (file size, type, etc.)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. DEDUPLICATION CHECK                                      â”‚
â”‚    Location: app/services/deduplication/                    â”‚
â”‚    - Generate content hash (SHA-256)                        â”‚
â”‚    - Check if already exists in documents table             â”‚
â”‚    - Skip if duplicate (based on content similarity)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. FILE STORAGE (Supabase Storage)                         â”‚
â”‚    - Upload original file to bucket: 'documents'            â”‚
â”‚    - Path: tenant_id/source/year/month/uuid_filename       â”‚
â”‚    - Get public URL for file download                       â”‚
â”‚    - Fallback: If storage fails, save as base64 in JSONB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. SAVE TO DOCUMENTS TABLE (Supabase PostgreSQL)           â”‚
â”‚    Table: documents                                          â”‚
â”‚    Columns:                                                  â”‚
â”‚      - id (auto-increment)                                  â”‚
â”‚      - tenant_id (user ID)                                  â”‚
â”‚      - source (gmail/gdrive/upload/slack)                   â”‚
â”‚      - source_id (external ID from source)                  â”‚
â”‚      - document_type (email/pdf/file/attachment)            â”‚
â”‚      - title (subject/filename)                             â”‚
â”‚      - content (extracted plain text)                       â”‚
â”‚      - content_hash (for deduplication)                     â”‚
â”‚      - file_url (Supabase Storage URL)                      â”‚
â”‚      - file_type, file_size, mime_type                      â”‚
â”‚      - metadata (JSONB - parsing info)                      â”‚
â”‚      - raw_data (JSONB - original data from source)         â”‚
â”‚      - parent_document_id (for attachments)                 â”‚
â”‚                                                              â”‚
â”‚    This is the SOURCE OF TRUTH for all documents!          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. PROPERTY GRAPH INGESTION (Neo4j + Qdrant)               â”‚
â”‚    Location: app/services/ingestion/llamaindex/            â”‚
â”‚              ingestion_pipeline.py                           â”‚
â”‚                                                              â”‚
â”‚    A. TEXT CHUNKING                                         â”‚
â”‚       - Split text into chunks (SentenceSplitter)           â”‚
â”‚       - Chunk size: 1024 chars, overlap: 200 chars          â”‚
â”‚                                                              â”‚
â”‚    B. EMBEDDING                                             â”‚
â”‚       - Generate vector embeddings (OpenAI text-embedding-3)â”‚
â”‚       - Each chunk gets its own embedding vector            â”‚
â”‚                                                              â”‚
â”‚    C. QDRANT STORAGE (Vector Database)                     â”‚
â”‚       - Store chunks with embeddings                        â”‚
â”‚       - Metadata: document_id, chunk_index, source, etc.    â”‚
â”‚       - Enable semantic search ("find similar content")     â”‚
â”‚                                                              â”‚
â”‚    D. NEO4J STORAGE (Knowledge Graph)                      â”‚
â”‚       Step 1: Create Document Node                          â”‚
â”‚         - Properties: title, type, source, created_at       â”‚
â”‚         - Label: __Entity__                                 â”‚
â”‚                                                              â”‚
â”‚       Step 2: Entity Extraction (SchemaLLMPathExtractor)    â”‚
â”‚         Uses GPT-4o to extract:                             â”‚
â”‚         â€¢ Entities (10 types):                              â”‚
â”‚           - PERSON, COMPANY, ROLE, DEAL, TASK, MEETING     â”‚
â”‚           - PAYMENT, MATERIAL, CERTIFICATION, PROJECT       â”‚
â”‚                                                              â”‚
â”‚         â€¢ Relationships (17 types):                         â”‚
â”‚           - WORKS_FOR, REPORTS_TO, HAS_ROLE                â”‚
â”‚           - CLIENT_OF, VENDOR_OF, SUPPLIES_MATERIAL        â”‚
â”‚           - REQUIRES_MATERIAL, ATTENDED_MEETING            â”‚
â”‚           - etc. (manufacturing-focused)                    â”‚
â”‚                                                              â”‚
â”‚       Step 3: Create Entity Nodes + Relationships           â”‚
â”‚         - Person â†’ WORKS_FOR â†’ Company                     â”‚
â”‚         - Deal â†’ REQUIRES_MATERIAL â†’ Material              â”‚
â”‚         - Company â†’ SUPPLIES_MATERIAL â†’ Material           â”‚
â”‚         - Person â†’ ATTENDED_MEETING â†’ Meeting              â”‚
â”‚                                                              â”‚
â”‚       Step 4: Link Document to Entities                    â”‚
â”‚         - Document â†’ MENTIONS â†’ Entity                     â”‚
â”‚         - Enables: "Show all docs mentioning John Doe"     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. HOURLY ENTITY DEDUPLICATION (Neo4j only)                â”‚
â”‚    - Find similar entities (vector similarity > 0.92)       â”‚
â”‚    - Verify with Levenshtein distance (< 3 chars)           â”‚
â”‚    - Merge duplicates with apoc.refactor.mergeNodes         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. INDEXING COMPLETE âœ…                                    â”‚
â”‚     File is now searchable via:                             â”‚
â”‚     â€¢ Vector search (Qdrant) - semantic similarity          â”‚
â”‚     â€¢ Graph queries (Neo4j) - relationship traversal        â”‚
â”‚     â€¢ SQL queries (Supabase) - metadata filtering           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **FLOW 2: AI Search (Hybrid RAG)**

```
1. USER QUERY â†’ POST /api/v1/chat or /api/v1/search

2. HYBRID QUERY ENGINE (HybridQueryEngine)
   â””â”€> SubQuestionQueryEngine breaks down complex questions

3. PARALLEL RETRIEVAL
   â”œâ”€> VectorStoreIndex (Qdrant):
   â”‚   â”œâ”€> Embed query with OpenAI
   â”‚   â”œâ”€> Semantic search over text chunks
   â”‚   â””â”€> Return top K similar chunks (default: 10)
   â”‚
   â””â”€> PropertyGraphIndex (Neo4j):
       â”œâ”€> Graph queries for relationships
       â”œâ”€> Entity lookups (PERSON, COMPANY, EMAIL)
       â””â”€> Return relevant entities + relationships

4. SYNTHESIS
   â”œâ”€> SubQuestionQueryEngine combines results
   â”œâ”€> GPT-4o-mini generates comprehensive answer
   â””â”€> Cites sources from both indexes

5. RESPONSE
   â””â”€> {answer, source_count, sources: [{node_id, text, score}]}
```

---

## ğŸ—‚ï¸ Codebase Structure

```
cortex/
â”œâ”€â”€ main.py                              # FastAPI entry point
â”‚
â”œâ”€â”€ app/                                 # Main application
â”‚   â”œâ”€â”€ core/                            # Infrastructure
â”‚   â”‚   â”œâ”€â”€ config.py                    # Pydantic Settings (all env vars)
â”‚   â”‚   â”œâ”€â”€ dependencies.py              # DI (HTTP, Supabase, RAG pipeline)
â”‚   â”‚   â””â”€â”€ security.py                  # JWT + API key auth
â”‚   â”‚
â”‚   â”œâ”€â”€ middleware/                      # Request processing
â”‚   â”‚   â”œâ”€â”€ error_handler.py             # Global exception handling
â”‚   â”‚   â”œâ”€â”€ logging.py                   # Request logging
â”‚   â”‚   â””â”€â”€ cors.py                      # CORS configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ models/schemas/                  # Pydantic models
â”‚   â”‚   â”œâ”€â”€ connector.py                 # OAuth, webhooks
â”‚   â”‚   â”œâ”€â”€ sync.py                      # Sync operations
â”‚   â”‚   â”œâ”€â”€ search.py                    # Search request/response
â”‚   â”‚   â”œâ”€â”€ ingestion.py                 # Document models
â”‚   â”‚   â””â”€â”€ knowledge_graph.py           # Graph entity types
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                        # Business logic
â”‚   â”‚   â”œâ”€â”€ connectors/                  # Data connectors
â”‚   â”‚   â”‚   â”œâ”€â”€ gmail.py                 # Gmail normalization
â”‚   â”‚   â”‚   â”œâ”€â”€ google_drive.py          # Drive file handling
â”‚   â”‚   â”‚   â””â”€â”€ microsoft_graph.py       # Outlook sync
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ nango/                       # OAuth & sync
â”‚   â”‚   â”‚   â”œâ”€â”€ nango_client.py          # Nango API client
â”‚   â”‚   â”‚   â”œâ”€â”€ drive_client.py          # Drive-specific actions
â”‚   â”‚   â”‚   â”œâ”€â”€ drive_sync.py            # Drive sync engine
â”‚   â”‚   â”‚   â”œâ”€â”€ sync_engine.py           # Email sync orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py              # Connection management
â”‚   â”‚   â”‚   â””â”€â”€ persistence.py           # Data persistence
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ingestion/                   # RAG pipeline
â”‚   â”‚   â”‚   â””â”€â”€ llamaindex/
â”‚   â”‚   â”‚       â”œâ”€â”€ config.py            # LlamaIndex configuration
â”‚   â”‚   â”‚       â”œâ”€â”€ ingestion_pipeline.py # Universal ingestion
â”‚   â”‚   â”‚       â””â”€â”€ query_engine.py      # Hybrid query engine
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ parsing/                     # File parsing
â”‚   â”‚   â”‚   â””â”€â”€ file_parser.py           # Universal file parser (lazy-loaded)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ deduplication/               # Deduplication
â”‚   â”‚   â”‚   â”œâ”€â”€ dedupe_service.py        # Content deduplication (SHA256)
â”‚   â”‚   â”‚   â””â”€â”€ entity_deduplication.py  # Entity deduplication (vector similarity)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ universal/                   # Universal ingestion
â”‚   â”‚   â”‚   â””â”€â”€ ingest.py                # Unified ingestion flow
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ search/                      # (Reserved for future query rewriting)
â”‚   â”‚
â”‚   â””â”€â”€ api/v1/routes/                   # API endpoints (v1)
â”‚       â”œâ”€â”€ health.py                    # Health checks
â”‚       â”œâ”€â”€ oauth.py                     # OAuth flow (Gmail/Drive/Outlook)
â”‚       â”œâ”€â”€ webhook.py                   # Nango webhooks
â”‚       â”œâ”€â”€ sync.py                      # Manual sync endpoints
â”‚       â”œâ”€â”€ search.py                    # Hybrid RAG search
â”‚       â”œâ”€â”€ emails.py                    # Email retrieval
â”‚       â”œâ”€â”€ upload.py                    # File upload
â”‚       â””â”€â”€ chat.py                      # Chat interface
â”‚
â”œâ”€â”€ connectorfrontend/                   # Next.js frontend
â”‚   â”œâ”€â”€ app/                             # App router
â”‚   â”‚   â”œâ”€â”€ page.tsx                     # Main chat page
â”‚   â”‚   â”œâ”€â”€ connections/page.tsx         # OAuth & sync UI
â”‚   â”‚   â””â”€â”€ login/page.tsx               # Auth page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ sidebar.tsx                  # Navigation sidebar
â”‚   â”œâ”€â”€ contexts/
â”‚   â”‚   â””â”€â”€ auth-context.tsx             # Supabase auth
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ api.ts                       # Backend API client
â”‚
â”œâ”€â”€ scripts/                             # Utility scripts
â”‚   â”œâ”€â”€ database_tools/                  # DB inspection
â”‚   â”œâ”€â”€ ingestion/                       # Data ingestion
â”‚   â””â”€â”€ testing/                         # Test scripts
â”‚
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ runtime.txt                          # Python 3.13
â””â”€â”€ README.md                            # This file
```

---

## ğŸ”Œ API Endpoints (v1)

### **OAuth & Connections**

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `GET /` | GET | None | API info |
| `GET /health` | GET | None | Health check |
| `GET /status` | GET | JWT | Connection status (Gmail/Drive/Outlook) |
| `GET /connect/start?provider={gmail\|google-drive\|outlook}` | GET | JWT | Initiate OAuth |
| `POST /nango/webhook` | POST | None | Nango auth/sync webhook |

### **Data Sync**

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `GET /sync/once` | GET | JWT | Manual Outlook sync |
| `GET /sync/once/gmail` | GET | JWT | Manual Gmail sync |
| `GET /sync/once/drive?folder_ids=id1,id2` | GET | JWT | Manual Drive sync |

### **Search & Chat**

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `POST /api/v1/search` | POST | JWT + API Key | Hybrid RAG search |
| `POST /api/v1/chat` | POST | JWT | Chat interface |

### **File Management**

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `POST /api/v1/upload/file` | POST | JWT + API Key | Upload file for ingestion |
| `GET /api/v1/emails/{episode_id}` | GET | JWT | Get full email by episode ID |

---

## ğŸš€ Quick Start

### **Prerequisites**

- Python 3.13+
- PostgreSQL (Supabase)
- Qdrant Cloud account
- Neo4j Aura database
- OpenAI API key
- Nango account

### **Installation**

```bash
# Clone repo
git clone https://github.com/ThunderbirdLabs/CORTEX.git
cd CORTEX

# Install dependencies
pip install -r requirements.txt

# Set environment variables (see .env.example)

# Run locally
uvicorn main:app --host 0.0.0.0 --port 8080 --reload
```

### **Environment Variables**

```bash
# Server
ENVIRONMENT=production
PORT=8080

# Database (Supabase)
DATABASE_URL=postgresql://...
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=...
SUPABASE_SERVICE_KEY=...

# Nango OAuth
NANGO_SECRET=...
NANGO_PROVIDER_KEY_GMAIL=gmail-connector
NANGO_PROVIDER_KEY_GOOGLE_DRIVE=google-drive  # Optional, falls back to gmail
NANGO_PROVIDER_KEY_OUTLOOK=outlook-connector

# RAG System
QDRANT_URL=https://...
QDRANT_API_KEY=...
QDRANT_COLLECTION_NAME=cortex_documents
NEO4J_URI=neo4j+s://...
NEO4J_PASSWORD=...
OPENAI_API_KEY=sk-proj-...

# API Keys
CORTEX_API_KEY=your-search-api-key
```

### **Database Setup**

Run SQL migrations in Supabase:

```sql
-- Documents table (unified storage)
CREATE TABLE documents (
  id BIGSERIAL PRIMARY KEY,
  tenant_id TEXT NOT NULL,
  source TEXT NOT NULL,
  source_id TEXT NOT NULL,
  document_type TEXT NOT NULL,
  title TEXT NOT NULL,
  content TEXT NOT NULL,
  content_hash TEXT,  -- For deduplication
  raw_data JSONB,
  file_type TEXT,
  file_size BIGINT,
  source_created_at TIMESTAMPTZ,
  source_modified_at TIMESTAMPTZ,
  ingested_at TIMESTAMPTZ DEFAULT NOW(),
  metadata JSONB,
  UNIQUE(tenant_id, source, source_id)
);

CREATE INDEX idx_documents_tenant ON documents(tenant_id);
CREATE INDEX idx_documents_content_hash ON documents(tenant_id, content_hash, source);
```

---

## ğŸ§ª Testing

### **Health Check**
```bash
curl https://your-app.onrender.com/health
```

### **Connection Status**
```bash
curl -H "Authorization: Bearer <jwt>" \
  https://your-app.onrender.com/status
```

### **Manual Drive Sync**
```bash
curl -H "Authorization: Bearer <jwt>" \
  "https://your-app.onrender.com/sync/once/drive"
```

### **RAG Search**
```bash
curl -X POST https://your-app.onrender.com/api/v1/search \
  -H "Authorization: Bearer <jwt>" \
  -H "X-API-Key: <api-key>" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the key points from the Q4 report?",
    "vector_limit": 5,
    "graph_limit": 5
  }'
```

---

## ğŸ” Security

### **Authentication**

1. **JWT (Supabase)** - User authentication
   - Used for: OAuth, sync, general API access
   - Header: `Authorization: Bearer <token>`

2. **API Key** - Search endpoint protection
   - Used for: `/api/v1/search`
   - Header: `X-API-Key: <key>`

### **Data Privacy**

- All user data isolated by `tenant_id`
- OAuth tokens managed by Nango (never stored in app)
- Content hashing for deduplication (SHA256)
- Supabase RLS policies (recommended)

---

## ğŸ”§ Key Features

### **Content Deduplication**
- SHA256 hash-based detection
- Prevents duplicate ingestion across sources
- Saves RAG processing costs
- Indexed for fast lookup

### **Incremental Sync**
- Google Drive: Uses `source_modified_at` timestamp
- Gmail: Cursor-based pagination
- Outlook: Delta links for changes only

### **Memory Optimization**
- Lazy-loaded PDF parser (no heavy ML at startup)
- Removed `unstructured[all-docs]` heavy dependencies
- Character limit (100k) per document
- Fits in Render's 512MB free tier

### **Enterprise Patterns**
- Dependency injection (FastAPI)
- Type-safe configuration (Pydantic)
- API versioning (`/api/v1/`)
- Centralized error handling
- Structured logging

---

## ğŸ› Troubleshooting

### **"Empty Response" in chat**
- No data indexed yet. Go to Connections â†’ Sync Gmail/Drive first

### **"Out of Memory" on Render**
- Verify you're on v0.4.5 (lazy-loaded parsers, optimized chunking)
- Check memory usage in Render dashboard
- Upgrade to paid tier if needed

### **Google Workspace files show garbled text**
- Fixed in v0.3.0+ - uses proper export MIME types
- Docs/Slides â†’ `text/plain`
- Sheets â†’ `text/csv`

### **"Column content_hash does not exist"**
- Run the database migration (see Database Setup)

---

## ğŸ“š Version History

### **v0.4.5 (Current) - Production RAG System**
- âœ… SchemaLLMPathExtractor with 10 entity types, 19 relationships
- âœ… Hybrid query engine (SubQuestionQueryEngine)
- âœ… Entity deduplication with vector similarity
- âœ… Unique document IDs prevent duplicate merging
- âœ… Production fixes (array IDs, encoding, 464 lines dead code removed)

### **v0.3.0 - Google Drive & Universal Ingestion**
- âœ… Google Drive OAuth & incremental sync
- âœ… Universal ingestion pipeline (any source â†’ RAG)
- âœ… Content-based deduplication (SHA256)
- âœ… Modern Aetheris-style frontend
- âœ… Memory optimizations (lazy loading, 512MB fit)

### **v0.2.0 - Enterprise Refactor**
- âœ… Unified backend architecture
- âœ… Dependency injection pattern
- âœ… Type-safe configuration

### **v0.1.0 - Initial Release**
- Email sync (Gmail/Outlook)
- Basic RAG search
- Frontend foundation

---

## ğŸ“ License

Proprietary - ThunderbirdLabs

---

**Built with â¤ï¸ by ThunderbirdLabs using FastAPI, LlamaIndex, Neo4j, Qdrant, and OpenAI**
