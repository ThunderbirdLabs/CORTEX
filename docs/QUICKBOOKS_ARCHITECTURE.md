# QuickBooks Integration Architecture - The Full Picture

## ğŸ§  Understanding Your Current System

### How Data Flows Today (Gmail/Outlook/Drive)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SYNC WORKER (Background Job via Dramatiq)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  sync_gmail_task() or sync_outlook_task() runs:                     â”‚
â”‚                                                                       â”‚
â”‚  â”œâ”€ Fetch emails from Nango unified API                             â”‚
â”‚  â”œâ”€ Spam filter (OpenAI classifier)                                  â”‚
â”‚  â””â”€ For each email:                                                  â”‚
â”‚      â””â”€ ingest_to_cortex() â†’                                        â”‚
â”‚          â””â”€ ingest_document_universal()                             â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. UNIVERSAL INGESTION (ingest_document_universal)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  Step 1: Extract text (if file â†’ parse with OCR)                    â”‚
â”‚  Step 2: Check duplicates (SHA-256 hash)                             â”‚
â”‚  Step 3: Save to Supabase `documents` table â† SOURCE OF TRUTH       â”‚
â”‚  Step 4: Call UniversalIngestionPipeline.ingest_document()          â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LLAMAINDEX PIPELINE (UniversalIngestionPipeline)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ A. VECTOR STORAGE (Qdrant)                            â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚  â€¢ Chunk text into ~1000 char pieces                  â”‚         â”‚
â”‚  â”‚  â€¢ Generate embeddings (OpenAI text-embedding-3-small)â”‚         â”‚
â”‚  â”‚  â€¢ Store in Qdrant with metadata:                     â”‚         â”‚
â”‚  â”‚    - document_id (links back to Supabase)            â”‚         â”‚
â”‚  â”‚    - created_at_timestamp (for recency filtering)    â”‚         â”‚
â”‚  â”‚    - source, document_type, title, etc.              â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ B. KNOWLEDGE GRAPH (Neo4j)                            â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚  â€¢ Extract entities with SchemaLLMPathExtractor       â”‚         â”‚
â”‚  â”‚    (GPT-4o-mini with your custom schema)             â”‚         â”‚
â”‚  â”‚                                                        â”‚         â”‚
â”‚  â”‚  â€¢ Entities extracted:                                â”‚         â”‚
â”‚  â”‚    PERSON, COMPANY, ROLE, DEAL, PAYMENT,             â”‚         â”‚
â”‚  â”‚    MATERIAL, CERTIFICATION                            â”‚         â”‚
â”‚  â”‚    (loaded from master Supabase company_schemas)     â”‚         â”‚
â”‚  â”‚                                                        â”‚         â”‚
â”‚  â”‚  â€¢ Creates nodes in Neo4j:                            â”‚         â”‚
â”‚  â”‚    (Sarah Chen:PERSON)                                â”‚         â”‚
â”‚  â”‚    (Acme Corp:COMPANY)                                â”‚         â”‚
â”‚  â”‚    (PO-2024-183:DEAL)                                 â”‚         â”‚
â”‚  â”‚    (Polycarbonate PC-1000:MATERIAL)                   â”‚         â”‚
â”‚  â”‚                                                        â”‚         â”‚
â”‚  â”‚  â€¢ Creates relationships:                             â”‚         â”‚
â”‚  â”‚    (Sarah)-[WORKS_FOR]->(Acme)                       â”‚         â”‚
â”‚  â”‚    (Acme)-[PLACED]->(PO-2024-183)                    â”‚         â”‚
â”‚  â”‚    (PO-2024-183)-[INCLUDES]->(Polycarbonate)         â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. RESULT: Data is Searchable                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  âœ… Semantic search via Qdrant (vector similarity)                   â”‚
â”‚  âœ… Graph queries via Neo4j (relationships)                          â”‚
â”‚  âœ… Hybrid search combines both for best results                     â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ How QuickBooks Should Work (Two Approaches)

### Approach A: Structured Financial Data (Recommended)

**QuickBooks data is STRUCTURED (not unstructured text like emails)**

Instead of ingesting into knowledge graph, store in Supabase and use for dashboard metrics:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QUICKBOOKS SYNC FLOW (Structured Data Approach)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£ NIGHTLY SYNC JOB (Dramatiq background task)
   â””â”€ fetch_all_quickbooks_data() â†’ Get invoices, bills, customers, etc.

2ï¸âƒ£ STORE IN SUPABASE (New table: quickbooks_cache)
   â””â”€ Cache entire QB response as JSONB
   â””â”€ Timestamp for freshness tracking

3ï¸âƒ£ CEO DASHBOARD READS FROM CACHE
   â””â”€ GET /dashboard/ceo â†’ Fetch cached QB data
   â””â”€ Calculate metrics (revenue, expenses, etc.)
   â””â”€ Search CORTEX knowledge graph for context

4ï¸âƒ£ RAG ENHANCEMENT (The Magic!)
   â””â”€ "Revenue: $47,500" â† From QuickBooks cache
   â””â”€ Search Qdrant: "invoices paid this week"
   â””â”€ Find: "Acme Corp paid Invoice #892 ($12.5k)" â† From emails!
   â””â”€ Link them together in dashboard
```

**Why This Approach:**
- âœ… QB data is already structured (JSON)
- âœ… Metrics calculated from source data (accurate)
- âœ… Fast dashboard load (cached data)
- âœ… RAG adds context from emails/docs
- âœ… No need to extract entities from structured data

**Schema:**
```sql
CREATE TABLE quickbooks_cache (
  id BIGSERIAL PRIMARY KEY,
  tenant_id TEXT NOT NULL,
  data_type TEXT NOT NULL,  -- 'full_dump', 'summary'
  data JSONB NOT NULL,       -- Entire QB response
  fetched_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(tenant_id, data_type)
);

CREATE INDEX idx_qb_cache_tenant ON quickbooks_cache(tenant_id);
```

---

### Approach B: Hybrid (QB + Knowledge Graph)

**If you want QB entities in Neo4j for graph queries:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QUICKBOOKS SYNC FLOW (Knowledge Graph Approach)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£ NIGHTLY SYNC JOB
   â””â”€ fetch_all_quickbooks_data()

2ï¸âƒ£ FOR EACH INVOICE/BILL/PAYMENT:
   â””â”€ Convert to "document" format
   â””â”€ Call ingest_document_universal()

3ï¸âƒ£ UNIVERSAL INGESTION PIPELINE:
   â”œâ”€ Save to documents table
   â””â”€ Extract entities:
       â€¢ CUSTOMER â†’ COMPANY node
       â€¢ INVOICE â†’ DEAL node
       â€¢ PAYMENT â†’ PAYMENT node

4ï¸âƒ£ NEO4J KNOWLEDGE GRAPH:
   â””â”€ (Acme Corp:COMPANY)-[OWES]->(Invoice #892:DEAL)
   â””â”€ (Invoice #892)-[PAID_BY]->(Payment #123:PAYMENT)

5ï¸âƒ£ GRAPH QUERIES:
   â””â”€ "Who owes us money?" â†’ Find unpaid invoices in graph
   â””â”€ "Show me all deals with Acme Corp" â†’ Graph traversal
```

**Why This Approach:**
- âœ… QB entities in knowledge graph
- âœ… Can query relationships ("Which customers haven't paid?")
- âœ… Unified search across emails + QB data
- âŒ More complex (need to format QB data as documents)
- âŒ Slower sync (entity extraction on every invoice)

---

## ğŸš€ Recommended Implementation (Approach A + RAG)

### Step 1: Create QuickBooks Cache Table

```sql
-- In Supabase
CREATE TABLE quickbooks_cache (
  id BIGSERIAL PRIMARY KEY,
  tenant_id TEXT NOT NULL,
  data_type TEXT NOT NULL,  -- 'invoices', 'bills', 'summary', 'full'
  data JSONB NOT NULL,
  fetched_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(tenant_id, data_type)
);

CREATE INDEX idx_qb_cache_tenant ON quickbooks_cache(tenant_id);
CREATE INDEX idx_qb_cache_fetched_at ON quickbooks_cache(fetched_at DESC);
```

### Step 2: Create Sync Worker

```python
# app/services/background/tasks.py

@dramatiq.actor(max_retries=3)
def sync_quickbooks_task(user_id: str, job_id: str):
    """
    Background job for QuickBooks sync.
    Fetches ALL QB data and caches in Supabase.
    """
    logger.info(f"ğŸš€ Starting QuickBooks sync job {job_id} for user {user_id}")

    http_client, supabase, _ = get_sync_dependencies()

    try:
        # Update job status
        supabase.table("sync_jobs").update({
            "status": "running",
            "started_at": "now()"
        }).eq("id", job_id).execute()

        # Fetch ALL QuickBooks data
        from app.services.integrations.quickbooks import fetch_all_quickbooks_data

        result = asyncio.run(fetch_all_quickbooks_data(
            http_client,
            user_id  # connection_id = user_id
        ))

        # Cache in Supabase
        supabase.table("quickbooks_cache").upsert({
            "tenant_id": user_id,
            "data_type": "full",
            "data": result,
            "fetched_at": "now()"
        }, on_conflict="tenant_id,data_type").execute()

        # Update job status
        supabase.table("sync_jobs").update({
            "status": "completed",
            "completed_at": "now()",
            "result": {
                "invoices_count": len(result.get("invoices", [])),
                "customers_count": len(result.get("customers", [])),
                "cached": True
            }
        }).eq("id", job_id).execute()

        logger.info(f"âœ… QuickBooks sync job {job_id} complete")
        return result

    except Exception as e:
        logger.error(f"âŒ QuickBooks sync job {job_id} failed: {e}")

        supabase.table("sync_jobs").update({
            "status": "failed",
            "completed_at": "now()",
            "error_message": str(e)
        }).eq("id", job_id).execute()

        raise
```

### Step 3: Create CEO Dashboard Endpoint

```python
# app/api/v1/routes/dashboard.py

@router.get("/dashboard/ceo")
async def get_ceo_dashboard(
    http_client: httpx.AsyncClient = Depends(get_http_client),
    supabase: Client = Depends(get_supabase),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    CEO dashboard with QuickBooks metrics + RAG context.

    Combines:
    1. Cached QuickBooks data (fast metrics)
    2. CORTEX RAG search (contextual insights)
    """
    user_id = current_user.get("id") or current_user.get("sub")

    # 1. Get cached QuickBooks data
    qb_cache = supabase.table("quickbooks_cache")\
        .select("data, fetched_at")\
        .eq("tenant_id", user_id)\
        .eq("data_type", "full")\
        .single()\
        .execute()

    if not qb_cache.data:
        raise HTTPException(status_code=404, detail="QuickBooks not synced yet")

    qb_data = qb_cache.data["data"]

    # 2. Calculate metrics from QB data
    invoices = qb_data.get("invoices", [])
    revenue = sum(float(inv.get("total", 0) or 0) for inv in invoices if float(inv.get("balance", 0) or 0) == 0)

    # 3. Search CORTEX for context (RAG!)
    from app.services.ingestion.llamaindex.query_engine import HybridQueryEngine

    query_engine = HybridQueryEngine()

    # Find emails about recent invoices
    context = await query_engine.query(
        "What invoices were paid this week? Show customer names and amounts.",
        filters={"source": ["gmail", "outlook"]}
    )

    return {
        "success": True,
        "quickbooks": {
            "revenue": revenue,
            "fetched_at": qb_cache.data["fetched_at"]
        },
        "context": {
            "recent_payments": context.response,
            "sources": [...]
        }
    }
```

### Step 4: Nightly Cron Job

Set up Render cron job:
```bash
# Every night at midnight
0 0 * * * python -m app.services.background.sync_quickbooks_cron
```

---

## ğŸ’¡ The Beautiful Part

### Widget Example: Revenue with Context

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’° Revenue This Week: $47,500 â–² 18%                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ From QuickBooks:                                       â”‚
â”‚ â€¢ 15 invoices paid                                     â”‚
â”‚ â€¢ $26,000 outstanding                                  â”‚
â”‚                                                         â”‚
â”‚ Recent Activity (from emails):                         â”‚
â”‚ âœ… Acme Corp paid Invoice #892 ($12,500)              â”‚
â”‚    ğŸ“§ "Payment confirmation received" - Oct 26        â”‚
â”‚                                                         â”‚
â”‚ âœ… Precision Plastics paid PO-2024-183 ($20,000)      â”‚
â”‚    ğŸ“§ "Wire transfer completed" - Oct 24              â”‚
â”‚                                                         â”‚
â”‚ â³ Superior Tooling Quote #445 pending ($15,000)      â”‚
â”‚    ğŸ“§ "Waiting on quality resolution" - Oct 27        â”‚
â”‚                                                         â”‚
â”‚ [View All Transactions] [Search Related Emails]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The Magic:**
- Numbers come from QuickBooks (accurate, real-time)
- Context comes from CORTEX (emails, communications)
- CEO sees both "what happened" AND "why/how"

---

## ğŸ¯ Decision Time

**Which approach should we build?**

### Option 1: Structured Cache (Recommended for CEO Dashboard)
- âœ… Fast
- âœ… Accurate metrics
- âœ… RAG enhancement for context
- âœ… Simple to implement
- âŒ QB data not in knowledge graph

### Option 2: Full Knowledge Graph Integration
- âœ… QB entities in Neo4j
- âœ… Unified graph queries
- âœ… Deep relationship analysis
- âŒ Slower sync
- âŒ More complex

### Option 3: Hybrid (Best of Both)
- âœ… Cache for dashboard metrics
- âœ… Selective entities in graph (e.g., major customers)
- âœ… Flexible querying
- âŒ Most complex

**My recommendation: Start with Option 1 (Structured Cache + RAG) for the CEO dashboard, then add Option 3 later if you need deep graph queries.**

---

## Next Steps

1. Create `quickbooks_cache` table in Supabase
2. Build `sync_quickbooks_task()` background job
3. Add `/dashboard/ceo` endpoint
4. Build frontend CEO dashboard with widgets
5. Test end-to-end flow

Ready to implement?
